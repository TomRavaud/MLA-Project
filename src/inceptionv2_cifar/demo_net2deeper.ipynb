{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Demo:** Net2DeeperNet on CIFAR with Inception-V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following demo shows how to apply Net2WDeeperNet to Inception-V2 in order to increase the number of output filters in each layer of the Inception blocks. The input image shape is the one of CIFAR-10 but the network and the Net2DeeperNet algorithm can be applied to any other image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchinfo\n",
    "import ssl\n",
    "\n",
    "# Import custom modules and packages\n",
    "from models.inceptionv2 import GoogleNetBN\n",
    "import params.inceptionv2_cifar\n",
    "import net2net.net2net_deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create an Inception-V2 model narrower than the original one\n",
    "\n",
    "We start by creating an Inception-V2 model, narrower than the standard model: the number of convolution channels at each layer within all Inception modules is reduced by a factor of $\\sqrt{0.3}$. The rest of the network remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\delpr\\miniconda3\\envs\\mla\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# Create a downsized version of the Inception-V2 network\n",
    "# (with 10 classes instead of 1000 for demo purposes)\n",
    "model = GoogleNetBN(nb_classes=10, inception_factor=np.sqrt(0.3))\n",
    "\n",
    "# Create a random input\n",
    "x = torch.randn(1,\n",
    "                params.inceptionv2_cifar.NB_CHANNELS,\n",
    "                *params.inceptionv2_cifar.IMAGE_SHAPE)\n",
    "\n",
    "# Compute the output of the teacher network\n",
    "# (forward pass to initialize the Lazy modules)\n",
    "y_teacher = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Expand the standard architecture of Inception-V2 using the Net2DeeperNet algorithm\n",
    "\n",
    " The algorithm is applied to the Inception modules and the fully-connected layer only, since the rest of the network is already standard. The weights and biases of the student model (the wider one) are initialized with those of the teacher model (the narrower one), in such a way that the output of the student model is the same as the output of the teacher model for the same input at initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to cifar-10-batches-py\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:33<00:00, 5029956.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting cifar-10-batches-py\\cifar-10-python.tar.gz to cifar-10-batches-py\n",
      "Files already downloaded and verified\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\delpr\\miniconda3\\envs\\mla\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 [train]: 100%|██████████| 313/313 [05:03<00:00,  1.03batch/s, batch_loss=2.5] \n"
     ]
    }
   ],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Instantiate a Net2Net object from a (pre-trained) model\n",
    "net2net = net2net.net2net_deeper.Net2Net(teacher_network=model, dataset_used=\"CIFAR10\")\n",
    "\n",
    "# Get the list of deepening operations\n",
    "deeper_operations = params.inceptionv2_cifar.deeper_operations\n",
    "\n",
    "# Add some noise to the copied weights (optional)\n",
    "sigma = 0.  # Standard deviation of the noise\n",
    "\n",
    "# Apply the Net2Net widening operations and get the student network\n",
    "net2net.net2deeper(deeper_operations)\n",
    "student_model = net2net.student_network\n",
    "\n",
    "# Compute the output of the student network\n",
    "y_student = student_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Check that the student and teacher models have the same output for the same input\n",
    "\n",
    "We check that the output of the student model is the same as the output of the teacher model for the same input at initialization. They can be slightly different if some noise has been added to the weights of the student model during the initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher output:  tensor([[ 0.1244,  0.1411, -0.1354, -0.0341,  0.1533, -0.1911,  0.1690, -0.3691,\n",
      "         -0.2764,  0.3873]], grad_fn=<AddmmBackward0>)\n",
      "Student output:  tensor([[ 1.3713e-01,  1.7307e-01, -1.1356e-01, -1.6519e-04,  1.2193e-01,\n",
      "         -1.9643e-01,  1.6833e-01, -3.5557e-01, -3.1146e-01,  3.5010e-01]],\n",
      "       grad_fn=<AddmmBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The outputs should be the same\n",
    "print(\"Teacher output: \", y_teacher)\n",
    "print(\"Student output: \", y_student, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Have a look at the student and teacher architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by displaying the architecture of the teacher model. We can check that the number of convolution channels at each layer within all Inception modules is reduced by a factor of $\\sqrt{0.3}$. The model has $1.886.577$ trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "GoogleNetBN                                   [1, 10]                   --\n",
       "├─Sequential: 1-1                             [1, 10]                   --\n",
       "│    └─Sequential: 2-1                        [1, 64, 9, 9]             --\n",
       "│    │    └─Conv2d: 3-1                       [1, 64, 17, 17]           9,472\n",
       "│    │    └─BatchNorm2d: 3-2                  [1, 64, 17, 17]           128\n",
       "│    │    └─ReLU: 3-3                         [1, 64, 17, 17]           --\n",
       "│    │    └─MaxPool2d: 3-4                    [1, 64, 9, 9]             --\n",
       "│    └─Sequential: 2-2                        [1, 192, 5, 5]            --\n",
       "│    │    └─Conv2d: 3-5                       [1, 64, 9, 9]             4,160\n",
       "│    │    └─BatchNorm2d: 3-6                  [1, 64, 9, 9]             128\n",
       "│    │    └─ReLU: 3-7                         [1, 64, 9, 9]             --\n",
       "│    │    └─Conv2d: 3-8                       [1, 192, 9, 9]            110,784\n",
       "│    │    └─BatchNorm2d: 3-9                  [1, 192, 9, 9]            384\n",
       "│    │    └─ReLU: 3-10                        [1, 192, 9, 9]            --\n",
       "│    │    └─MaxPool2d: 3-11                   [1, 192, 5, 5]            --\n",
       "│    └─Sequential: 2-3                        [1, 262, 3, 3]            --\n",
       "│    │    └─InceptionBN: 3-12                 [1, 139, 5, 5]            58,261\n",
       "│    │    └─InceptionBN: 3-13                 [1, 262, 5, 5]            115,985\n",
       "│    │    └─MaxPool2d: 3-14                   [1, 262, 3, 3]            --\n",
       "│    └─Sequential: 2-4                        [1, 455, 2, 2]            --\n",
       "│    │    └─InceptionBN: 3-15                 [1, 279, 3, 3]            111,501\n",
       "│    │    └─InceptionBN: 3-16                 [1, 279, 3, 3]            134,096\n",
       "│    │    └─InceptionBN: 3-17                 [1, 280, 3, 3]            153,116\n",
       "│    │    └─InceptionBN: 3-18                 [1, 288, 3, 3]            179,718\n",
       "│    │    └─InceptionBN: 3-19                 [1, 455, 3, 3]            258,884\n",
       "│    │    └─MaxPool2d: 3-20                   [1, 455, 2, 2]            --\n",
       "│    └─Sequential: 2-5                        [1, 560]                  --\n",
       "│    │    └─InceptionBN: 3-21                 [1, 455, 2, 2]            311,322\n",
       "│    │    └─InceptionBN: 3-22                 [1, 560, 2, 2]            433,028\n",
       "│    │    └─AdaptiveAvgPool2d: 3-23           [1, 560, 1, 1]            --\n",
       "│    │    └─Flatten: 3-24                     [1, 560]                  --\n",
       "│    └─Linear: 2-6                            [1, 10]                   5,610\n",
       "===============================================================================================\n",
       "Total params: 1,886,577\n",
       "Trainable params: 1,886,577\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 26.86\n",
       "===============================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.21\n",
       "Params size (MB): 7.55\n",
       "Estimated Total Size (MB): 8.77\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the architecture of the student network\n",
    "torchinfo.summary(model, input_size=(1,\n",
    "                                     params.inceptionv2_cifar.NB_CHANNELS,\n",
    "                                     *params.inceptionv2_cifar.IMAGE_SHAPE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then display the architecture of the student model. We can check that the number of convolution channels at each layer within all Inception modules is the same as the standard model. The model has $5.998.362$ trainable parameters. Thus, the number of parameters in the teacher model is about $31.5\\%$ of the number of parameters in the student model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "GoogleNetBN                                   [1, 10]                   --\n",
       "├─Sequential: 1-1                             [1, 10]                   --\n",
       "│    └─Sequential: 2-1                        [1, 64, 9, 9]             --\n",
       "│    │    └─Conv2d: 3-1                       [1, 64, 17, 17]           9,472\n",
       "│    │    └─BatchNorm2d: 3-2                  [1, 64, 17, 17]           128\n",
       "│    │    └─ReLU: 3-3                         [1, 64, 17, 17]           --\n",
       "│    │    └─MaxPool2d: 3-4                    [1, 64, 9, 9]             --\n",
       "│    └─Sequential: 2-2                        [1, 192, 5, 5]            --\n",
       "│    │    └─Conv2d: 3-5                       [1, 64, 9, 9]             4,160\n",
       "│    │    └─BatchNorm2d: 3-6                  [1, 64, 9, 9]             128\n",
       "│    │    └─ReLU: 3-7                         [1, 64, 9, 9]             --\n",
       "│    │    └─Conv2d: 3-8                       [1, 192, 9, 9]            110,784\n",
       "│    │    └─BatchNorm2d: 3-9                  [1, 192, 9, 9]            384\n",
       "│    │    └─ReLU: 3-10                        [1, 192, 9, 9]            --\n",
       "│    │    └─MaxPool2d: 3-11                   [1, 192, 5, 5]            --\n",
       "│    └─Sequential: 2-3                        [1, 262, 3, 3]            --\n",
       "│    │    └─InceptionBN: 3-12                 [1, 139, 5, 5]            65,827\n",
       "│    │    └─InceptionBN: 3-13                 [1, 262, 5, 5]            133,325\n",
       "│    │    └─MaxPool2d: 3-14                   [1, 262, 3, 3]            --\n",
       "│    └─Sequential: 2-4                        [1, 455, 2, 2]            --\n",
       "│    │    └─InceptionBN: 3-15                 [1, 279, 3, 3]            130,067\n",
       "│    │    └─InceptionBN: 3-16                 [1, 279, 3, 3]            151,480\n",
       "│    │    └─InceptionBN: 3-17                 [1, 280, 3, 3]            170,192\n",
       "│    │    └─InceptionBN: 3-18                 [1, 288, 3, 3]            198,268\n",
       "│    │    └─InceptionBN: 3-19                 [1, 455, 3, 3]            300,354\n",
       "│    │    └─MaxPool2d: 3-20                   [1, 455, 2, 2]            --\n",
       "│    └─Sequential: 2-5                        [1, 560]                  --\n",
       "│    │    └─InceptionBN: 3-21                 [1, 455, 2, 2]            352,792\n",
       "│    │    └─InceptionBN: 3-22                 [1, 560, 2, 2]            507,056\n",
       "│    │    └─AdaptiveAvgPool2d: 3-23           [1, 560, 1, 1]            --\n",
       "│    │    └─Flatten: 3-24                     [1, 560]                  --\n",
       "│    └─Linear: 2-6                            [1, 10]                   5,610\n",
       "===============================================================================================\n",
       "Total params: 2,140,027\n",
       "Trainable params: 2,140,027\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 28.91\n",
       "===============================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.67\n",
       "Params size (MB): 8.56\n",
       "Estimated Total Size (MB): 10.25\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the architecture of the student network\n",
    "torchinfo.summary(student_model, input_size=(1,\n",
    "                                             params.inceptionv2_cifar.NB_CHANNELS,\n",
    "                                             *params.inceptionv2_cifar.IMAGE_SHAPE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
