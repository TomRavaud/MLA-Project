{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Demo:** Net2DeeperNet on MNIST with LeNet5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following demo shows how to apply Net2DeeperNet to LeNet5 in order to deeper a convolutional layer. The input image shape is the one of MNIST, but the network and the Net2DeeperNet algorithm can be applied to any other image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torchinfo\n",
    "\n",
    "# Import custom modules and packages\n",
    "from models.lenet import LeNet\n",
    "import params.lenet_mnist\n",
    "import net2net.net2net_deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a LeNet5 model\n",
    "\n",
    "We start by creating the standard LeNet5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LeNet model\n",
    "model = LeNet(nb_classes=params.lenet_mnist.NB_CLASSES)\n",
    "\n",
    "# Create a random input\n",
    "x = torch.randn(1,\n",
    "                params.lenet_mnist.NB_CHANNELS,\n",
    "                *params.lenet_mnist.IMAGE_SHAPE)\n",
    "\n",
    "# Compute the output of the teacher network\n",
    "y_teacher = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a wider version of LeNet5\n",
    "\n",
    "We then apply the Net2DeeperNet algorithm to the standard LeNet5 model to increase the number of output filters of the first convolutional layer. The weights and biases of the student model are initialized with those of the teacher model, in such a way that the output of the student model is the same as the output of the teacher model for the same input at initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\delpr\\miniconda3\\envs\\mla\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "The weights and bias of the new batch normalization layer arenot initialized yet. To be implemented.\n",
      "Device: cpu\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 [train]: 100%|██████████| 782/782 [01:17<00:00, 10.14batch/s, batch_loss=2.24] \n"
     ]
    }
   ],
   "source": [
    "# Instantiate a Net2Net object from a (pre-trained) model\n",
    "net2net = net2net.net2net_deeper.Net2Net(teacher_network=model,dataset_used=\"MNIST\")\n",
    "\n",
    "# Set the deepening operations to be performed\n",
    "# Here we only increase the width of the first convolutional layer\n",
    "deeper_operations = {\"operation1\": {\"target_conv_layers\": [\"layer1.0\",\"layer2.0\"]}}\n",
    "\n",
    "# Add some noise to the copied weights (optional)\n",
    "sigma = 0.  # Standard deviation of the noise\n",
    "\n",
    "# Apply the Net2Net deepening operations and get the student network\n",
    "net2net.net2deeper(deeper_operations)\n",
    "student_model = net2net.student_network\n",
    "\n",
    "# Compute the output of the student network\n",
    "y_student = student_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Check that the student and teacher models have the same output for the same input\n",
    "\n",
    "We check that the output of the student model is the same as the output of the teacher model for the same input at initialization. They can be slightly different if some noise has been added to the weights of the student model during the initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher output:  tensor([[ 0.1087,  0.1175,  0.1888,  0.2984,  0.0080,  0.0870, -0.1261,  0.0786,\n",
      "          0.0226, -0.1650]], grad_fn=<AddmmBackward0>)\n",
      "Student output:  tensor([[ 0.4720,  1.2754,  2.6164,  3.6586,  0.4364,  2.1904, -0.3835,  1.4233,\n",
      "          0.8637, -1.1186]], grad_fn=<AddmmBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The outputs should be the same\n",
    "print(\"Teacher output: \", y_teacher)\n",
    "print(\"Student output: \", y_student, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Have a look at the student and teacher architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the student and teacher architectures to check that the student model has more filters than the teacher model in the first convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LeNet                                    [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 6, 14, 14]            --\n",
       "│    └─Conv2d: 2-1                       [1, 6, 28, 28]            156\n",
       "│    └─BatchNorm2d: 2-2                  [1, 6, 28, 28]            12\n",
       "│    └─ReLU: 2-3                         [1, 6, 28, 28]            --\n",
       "│    └─MaxPool2d: 2-4                    [1, 6, 14, 14]            --\n",
       "├─Sequential: 1-2                        [1, 16, 5, 5]             --\n",
       "│    └─Conv2d: 2-5                       [1, 16, 10, 10]           2,416\n",
       "│    └─BatchNorm2d: 2-6                  [1, 16, 10, 10]           32\n",
       "│    └─ReLU: 2-7                         [1, 16, 10, 10]           --\n",
       "│    └─MaxPool2d: 2-8                    [1, 16, 5, 5]             --\n",
       "├─Linear: 1-3                            [1, 120]                  48,120\n",
       "├─ReLU: 1-4                              [1, 120]                  --\n",
       "├─Linear: 1-5                            [1, 84]                   10,164\n",
       "├─ReLU: 1-6                              [1, 84]                   --\n",
       "├─Linear: 1-7                            [1, 10]                   850\n",
       "==========================================================================================\n",
       "Total params: 61,750\n",
       "Trainable params: 61,750\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.42\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.10\n",
       "Params size (MB): 0.25\n",
       "Estimated Total Size (MB): 0.35\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the architecture of the student network\n",
    "torchinfo.summary(model, input_size=(1,\n",
    "                                     params.lenet_mnist.NB_CHANNELS,\n",
    "                                     *params.lenet_mnist.IMAGE_SHAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LeNet                                    [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 6, 14, 14]            --\n",
       "│    └─Conv2d: 2-1                       [1, 6, 28, 28]            156\n",
       "│    └─BatchNorm2d: 2-2                  [1, 6, 28, 28]            12\n",
       "│    └─ReLU: 2-3                         [1, 6, 28, 28]            --\n",
       "│    └─Conv2d: 2-4                       [1, 6, 28, 28]            906\n",
       "│    └─BatchNorm2d: 2-5                  [1, 6, 28, 28]            12\n",
       "│    └─ReLU: 2-6                         [1, 6, 28, 28]            --\n",
       "│    └─MaxPool2d: 2-7                    [1, 6, 14, 14]            --\n",
       "├─Sequential: 1-2                        [1, 16, 5, 5]             --\n",
       "│    └─Conv2d: 2-8                       [1, 16, 10, 10]           2,416\n",
       "│    └─BatchNorm2d: 2-9                  [1, 16, 10, 10]           32\n",
       "│    └─ReLU: 2-10                        [1, 16, 10, 10]           --\n",
       "│    └─Conv2d: 2-11                      [1, 16, 10, 10]           6,416\n",
       "│    └─BatchNorm2d: 2-12                 [1, 16, 10, 10]           32\n",
       "│    └─ReLU: 2-13                        [1, 16, 10, 10]           --\n",
       "│    └─MaxPool2d: 2-14                   [1, 16, 5, 5]             --\n",
       "├─Linear: 1-3                            [1, 120]                  48,120\n",
       "├─ReLU: 1-4                              [1, 120]                  --\n",
       "├─Linear: 1-5                            [1, 84]                   10,164\n",
       "├─ReLU: 1-6                              [1, 84]                   --\n",
       "├─Linear: 1-7                            [1, 10]                   850\n",
       "==========================================================================================\n",
       "Total params: 69,116\n",
       "Trainable params: 69,116\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.78\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.20\n",
       "Params size (MB): 0.28\n",
       "Estimated Total Size (MB): 0.48\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the architecture of the student network\n",
    "torchinfo.summary(net2net.student_network, input_size=(1,\n",
    "                                                       params.lenet_mnist.NB_CHANNELS,\n",
    "                                                       *params.lenet_mnist.IMAGE_SHAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
