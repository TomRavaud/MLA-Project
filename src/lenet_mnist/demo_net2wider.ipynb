{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Demo:** Net2WiderNet on MNIST with LeNet5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following demo shows how to apply Net2WiderNet to LeNet5 in order to increase the number of output filters of a convolutional layer. The input image shape is the one of MNIST, but the network and the Net2WiderNet algorithm can be applied to any other image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torchinfo\n",
    "\n",
    "# Import custom modules and packages\n",
    "from lenet import LeNet\n",
    "import params.lenet_mnist\n",
    "import net2net.net2net_wider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a LeNet5 model\n",
    "\n",
    "We start by creating the standard LeNet5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LeNet model\n",
    "model = LeNet(nb_classes=params.lenet_mnist.NB_CLASSES)\n",
    "\n",
    "# Create a random input\n",
    "x = torch.randn(1,\n",
    "                params.lenet_mnist.NB_CHANNELS,\n",
    "                *params.lenet_mnist.IMAGE_SHAPE)\n",
    "\n",
    "# Compute the output of the teacher network\n",
    "y_teacher = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a wider version of LeNet5\n",
    "\n",
    "We then apply the Net2WiderNet algorithm to the standard LeNet5 model to increase the number of output filters of the first convolutional layer. The weights and biases of the student model are initialized with those of the teacher model, in such a way that the output of the student model is the same as the output of the teacher model for the same input at initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Widening operation:  operation1\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a Net2Net object from a (pre-trained) model\n",
    "net2net = net2net.net2net_wider.Net2Net(teacher_network=model)\n",
    "\n",
    "# Set the widening operations to be performed\n",
    "# Here we only increase the width of the first convolutional layer\n",
    "wider_operations = {\"operation1\": {\"target_conv_layers\": [\"layer1.0\"],\n",
    "                    \"width\": [10],\n",
    "                    \"batch_norm_layers\": [\"layer1.1\"],\n",
    "                    \"next_layers\": [\"layer2.0\"]}}\n",
    "\n",
    "# Add some noise to the copied weights (optional)\n",
    "sigma = 0.  # Standard deviation of the noise\n",
    "\n",
    "\n",
    "# Go through the list of widening operations\n",
    "for key in wider_operations.keys():\n",
    "\n",
    "    print(\"Widening operation: \", key)\n",
    "    \n",
    "    # Get the parameters of the wider operation\n",
    "    target_conv_layers = wider_operations[key][\"target_conv_layers\"]\n",
    "    next_layer = wider_operations[key][\"next_layers\"]\n",
    "    new_width = wider_operations[key][\"width\"]\n",
    "    batch_norm_layers = wider_operations[key][\"batch_norm_layers\"]\n",
    "\n",
    "    # Widen a layer of the network\n",
    "    net2net.net2wider(target_conv_layers=target_conv_layers,\n",
    "                      next_layers=next_layer,\n",
    "                      width=new_width,\n",
    "                      batch_norm_layers=batch_norm_layers,\n",
    "                      sigma=sigma)\n",
    "\n",
    "\n",
    "# Compute the output of the student network\n",
    "y_student = net2net.student_network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Check that the student and teacher models have the same output for the same input\n",
    "\n",
    "We check that the output of the student model is the same as the output of the teacher model for the same input at initialization. They can be slightly different if some noise has been added to the weights of the student model during the initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher output:  tensor([[ 0.0497,  0.1230,  0.2026, -0.0270,  0.0548,  0.0403,  0.0751,  0.0564,\n",
      "          0.1223,  0.0191]], grad_fn=<AddmmBackward0>)\n",
      "Student output:  tensor([[ 0.0497,  0.1230,  0.2026, -0.0270,  0.0548,  0.0403,  0.0751,  0.0564,\n",
      "          0.1223,  0.0191]], grad_fn=<AddmmBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The outputs should be the same\n",
    "print(\"Teacher output: \", y_teacher)\n",
    "print(\"Student output: \", y_student, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Have a look at the student and teacher architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the student and teacher architectures to check that the student model has more filters than the teacher model in the first convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LeNet                                    [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 6, 14, 14]            --\n",
       "│    └─Conv2d: 2-1                       [1, 6, 28, 28]            156\n",
       "│    └─BatchNorm2d: 2-2                  [1, 6, 28, 28]            12\n",
       "│    └─ReLU: 2-3                         [1, 6, 28, 28]            --\n",
       "│    └─MaxPool2d: 2-4                    [1, 6, 14, 14]            --\n",
       "├─Sequential: 1-2                        [1, 16, 5, 5]             --\n",
       "│    └─Conv2d: 2-5                       [1, 16, 10, 10]           2,416\n",
       "│    └─BatchNorm2d: 2-6                  [1, 16, 10, 10]           32\n",
       "│    └─ReLU: 2-7                         [1, 16, 10, 10]           --\n",
       "│    └─MaxPool2d: 2-8                    [1, 16, 5, 5]             --\n",
       "├─Linear: 1-3                            [1, 120]                  48,120\n",
       "├─ReLU: 1-4                              [1, 120]                  --\n",
       "├─Linear: 1-5                            [1, 84]                   10,164\n",
       "├─ReLU: 1-6                              [1, 84]                   --\n",
       "├─Linear: 1-7                            [1, 10]                   850\n",
       "==========================================================================================\n",
       "Total params: 61,750\n",
       "Trainable params: 61,750\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.42\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.10\n",
       "Params size (MB): 0.25\n",
       "Estimated Total Size (MB): 0.35\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the architecture of the student network\n",
    "torchinfo.summary(model, input_size=(1,\n",
    "                                     params.lenet_mnist.NB_CHANNELS,\n",
    "                                     *params.lenet_mnist.IMAGE_SHAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LeNet                                    [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 10, 14, 14]           --\n",
       "│    └─Conv2d: 2-1                       [1, 10, 28, 28]           260\n",
       "│    └─BatchNorm2d: 2-2                  [1, 10, 28, 28]           20\n",
       "│    └─ReLU: 2-3                         [1, 10, 28, 28]           --\n",
       "│    └─MaxPool2d: 2-4                    [1, 10, 14, 14]           --\n",
       "├─Sequential: 1-2                        [1, 16, 5, 5]             --\n",
       "│    └─Conv2d: 2-5                       [1, 16, 10, 10]           4,016\n",
       "│    └─BatchNorm2d: 2-6                  [1, 16, 10, 10]           32\n",
       "│    └─ReLU: 2-7                         [1, 16, 10, 10]           --\n",
       "│    └─MaxPool2d: 2-8                    [1, 16, 5, 5]             --\n",
       "├─Linear: 1-3                            [1, 120]                  48,120\n",
       "├─ReLU: 1-4                              [1, 120]                  --\n",
       "├─Linear: 1-5                            [1, 84]                   10,164\n",
       "├─ReLU: 1-6                              [1, 84]                   --\n",
       "├─Linear: 1-7                            [1, 10]                   850\n",
       "==========================================================================================\n",
       "Total params: 63,462\n",
       "Trainable params: 63,462\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.66\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.15\n",
       "Params size (MB): 0.25\n",
       "Estimated Total Size (MB): 0.41\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the architecture of the student network\n",
    "torchinfo.summary(net2net.student_network, input_size=(1,\n",
    "                                                       params.lenet_mnist.NB_CHANNELS,\n",
    "                                                       *params.lenet_mnist.IMAGE_SHAPE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
